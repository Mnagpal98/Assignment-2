{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "577b47dc",
   "metadata": {},
   "source": [
    "# Assignment-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "20691bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (4.7.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "232f9f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d0641c",
   "metadata": {},
   "source": [
    "Now we will download the webDriver for the web Browser.Steps for download are-\n",
    "1.Check the version of your browser\n",
    "2.go to the link https://chromedriver.chromium.org/downloads\n",
    "3.Download the web driver for your version of your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5da4b028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\HP\\Desktop\\internship\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dee9b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let connect tot he driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a1e67d",
   "metadata": {},
   "source": [
    "##### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a43379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page on automated chrome browser\n",
    "driver.get (\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e31d217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering the designation and location as required in the question-\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da1e010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca647672",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9f3747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe85e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from the given page\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#scraping company name for the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping Job experience for the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33f4d23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a1ab29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataframe from above data.\n",
    "df=pd.DataFrame({'Job_title':job_title,'job_location':job_location,'company_name':company_name,'Exp_required':experience_required})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f400a71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>MM STAFFING CAREER CONSULTANTS PRIVATE LIMITED</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst | Neiman Marcus Group</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Talent500</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Management Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>1-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Analyst - Data Management</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>MM STAFFING CAREER CONSULTANTS PRIVATE LIMITED</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sr Data Analyst - Tableau</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>S.A.W IT Services Pvt Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Project Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>WSP</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Job_title         job_location  \\\n",
       "0                               Data Analyst  Bangalore/Bengaluru   \n",
       "1                               Data Analyst  Bangalore/Bengaluru   \n",
       "2                           Sr. Data Analyst  Bangalore/Bengaluru   \n",
       "3  Senior Data Analyst | Neiman Marcus Group  Bangalore/Bengaluru   \n",
       "4                     Senior Data Analyst II  Bangalore/Bengaluru   \n",
       "5             Senior Data Management Analyst  Bangalore/Bengaluru   \n",
       "6           Senior Analyst - Data Management  Bangalore/Bengaluru   \n",
       "7                               Data Analyst  Bangalore/Bengaluru   \n",
       "8                  Sr Data Analyst - Tableau  Bangalore/Bengaluru   \n",
       "9                       Project Data Analyst  Bangalore/Bengaluru   \n",
       "\n",
       "                                     company_name Exp_required  \n",
       "0                                             ANZ      1-4 Yrs  \n",
       "1                                             ANZ      1-5 Yrs  \n",
       "2  MM STAFFING CAREER CONSULTANTS PRIVATE LIMITED      5-8 Yrs  \n",
       "3                                       Talent500     6-11 Yrs  \n",
       "4                                        Flipkart      2-4 Yrs  \n",
       "5                                     Wells Fargo     1-12 Yrs  \n",
       "6                                       Accenture      5-8 Yrs  \n",
       "7  MM STAFFING CAREER CONSULTANTS PRIVATE LIMITED      5-7 Yrs  \n",
       "8                       S.A.W IT Services Pvt Ltd      2-5 Yrs  \n",
       "9                                             WSP      0-4 Yrs  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8310e568",
   "metadata": {},
   "source": [
    "##### Q2:Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516ad7a1",
   "metadata": {},
   "source": [
    "##### Answer:- 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69a79860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let connect tot he driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e3e26b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page on automated chrome browser\n",
    "\n",
    "driver.get (\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c27d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering the designation and location as required in the question-\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e019ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2f4297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"keywordSugg\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d1a9f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "932913d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from the given page\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#scraping company name for the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping Job experience for the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de38440c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17f10cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataframe from above data.\n",
    "df=pd.DataFrame({'Job_title':job_title,'job_location':job_location,'company_name':company_name,'Exp_required':experience_required})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3b352ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi, Hyderabad/Secunderabad, Pune, Ahmed...</td>\n",
       "      <td>Tata Nexarc</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Nagpur, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / AI-ML Engineer</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hitachi Ltd.</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manager-Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACN - Applied Intelligence - Data Scientist - 09</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Noida, Kolkata, Hyderabad/Secunderaba...</td>\n",
       "      <td>Mindtree</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - II</td>\n",
       "      <td>India, Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>Bizongo</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Baker Hughes</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Science - Engineering Manager</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job_title  \\\n",
       "0                  Analystics & Modeling Specialist   \n",
       "1                                    Data Scientist   \n",
       "2                                    Data Scientist   \n",
       "3                   Data Scientist / AI-ML Engineer   \n",
       "4                              Manager-Data Science   \n",
       "5  ACN - Applied Intelligence - Data Scientist - 09   \n",
       "6                                    Data Scientist   \n",
       "7                               Data Scientist - II   \n",
       "8                             Senior Data Scientist   \n",
       "9                Data Science - Engineering Manager   \n",
       "\n",
       "                                        job_location      company_name  \\\n",
       "0  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...         Accenture   \n",
       "1  New Delhi, Hyderabad/Secunderabad, Pune, Ahmed...       Tata Nexarc   \n",
       "2                  Nagpur, Pune, Bangalore/Bengaluru     Tech Mahindra   \n",
       "3                                Bangalore/Bengaluru      Hitachi Ltd.   \n",
       "4                                Bangalore/Bengaluru  AMERICAN EXPRESS   \n",
       "5                                Bangalore/Bengaluru         Accenture   \n",
       "6  Hybrid - Noida, Kolkata, Hyderabad/Secunderaba...          Mindtree   \n",
       "7     India, Bangalore/Bengaluru, Mumbai (All Areas)           Bizongo   \n",
       "8                        Mumbai, Bangalore/Bengaluru      Baker Hughes   \n",
       "9                     New Delhi, Bangalore/Bengaluru             Paytm   \n",
       "\n",
       "  Exp_required  \n",
       "0      6-8 Yrs  \n",
       "1      4-8 Yrs  \n",
       "2      5-8 Yrs  \n",
       "3      3-7 Yrs  \n",
       "4      3-4 Yrs  \n",
       "5      2-6 Yrs  \n",
       "6     5-10 Yrs  \n",
       "7      3-6 Yrs  \n",
       "8      6-8 Yrs  \n",
       "9      3-5 Yrs  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63ce73f",
   "metadata": {},
   "source": [
    "##### Ques-3 In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b9e63",
   "metadata": {},
   "source": [
    "##### Answer-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "05a902e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let connect tot he driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6357692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page on automated chrome browser\n",
    "\n",
    "driver.get (\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "aeb10bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering the designation and location as required in the question-\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a46979c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Delhi/NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b2cc3f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"keywordSugg\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "be0c7625",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "job_salary=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "71198e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from the given page\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#scraping company name for the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping Job experience for the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "    \n",
    "#scraping Job salary for the given page\n",
    "salary_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi salary']\")\n",
    "for i in salary_tags[0:10]:\n",
    "    sal=i.text\n",
    "    job_salary.append(sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a868ba06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required),len(job_salary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "16d363f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataframe from above data.\n",
    "df=pd.DataFrame({'Job_title':job_title,'job_location':job_location,'company_name':company_name,'Exp_required':experience_required,'job_salary':job_salary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "c298b524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "      <th>job_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python Programming Language Data Science Pract...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Supply Chain</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cargill</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Artificial Intelligence/Computer Vision Engine...</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Vicara</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist/Sr. Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Synechron</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infosys</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Machine Learning Engineer II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Swiggy</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - 2</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>24 7 ai</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Job Opportunity For Data Scientists |TIBCO Sof...</td>\n",
       "      <td>Pune</td>\n",
       "      <td>TIBCO</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>2,00,000 - 7,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SnapLogic Data Science Practitioner</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Scientist</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Johnson &amp; Johnson</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Python Programming Language Data Science Pract...   \n",
       "1                      Data Scientist - Supply Chain   \n",
       "2  Artificial Intelligence/Computer Vision Engine...   \n",
       "3                  Data Scientist/Sr. Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                       Machine Learning Engineer II   \n",
       "6                                 Data Scientist - 2   \n",
       "7  Job Opportunity For Data Scientists |TIBCO Sof...   \n",
       "8                SnapLogic Data Science Practitioner   \n",
       "9                                          Scientist   \n",
       "\n",
       "                                        job_location       company_name  \\\n",
       "0                                Bangalore/Bengaluru          Accenture   \n",
       "1                                Bangalore/Bengaluru            Cargill   \n",
       "2  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...             Vicara   \n",
       "3                                Bangalore/Bengaluru          Synechron   \n",
       "4                                Bangalore/Bengaluru            Infosys   \n",
       "5                                Bangalore/Bengaluru             Swiggy   \n",
       "6                                Bangalore/Bengaluru            24 7 ai   \n",
       "7                                               Pune              TIBCO   \n",
       "8                                             Mumbai          Accenture   \n",
       "9                                             Mumbai  Johnson & Johnson   \n",
       "\n",
       "  Exp_required               job_salary  \n",
       "0      4-6 Yrs            Not disclosed  \n",
       "1      3-5 Yrs            Not disclosed  \n",
       "2      1-3 Yrs            Not disclosed  \n",
       "3     5-10 Yrs            Not disclosed  \n",
       "4      3-6 Yrs            Not disclosed  \n",
       "5      3-4 Yrs            Not disclosed  \n",
       "6      1-3 Yrs            Not disclosed  \n",
       "7      2-5 Yrs  2,00,000 - 7,00,000 PA.  \n",
       "8      2-4 Yrs            Not disclosed  \n",
       "9      4-8 Yrs            Not disclosed  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d03ac5",
   "metadata": {},
   "source": [
    "##### Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdfd450",
   "metadata": {},
   "source": [
    "##### Answer-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "30ee5603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let connect tot he driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "2910fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page on automated chrome browser\n",
    "\n",
    "driver.get (\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "850fbc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering the products and brand as required in the question-\n",
    "\n",
    "product=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "product.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "017e4044",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "12edf13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tags=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "38b360ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the brand of the product\n",
    "\n",
    "brand_tags=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "for i in brand_tags[0:100]:\n",
    "    brand=i.text\n",
    "    brand_tags.append(brand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "794532a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "next_page.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "e02dbd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brand_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "0a2740ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=brand_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "f460ed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataframe from above data.\n",
    "df=pd.DataFrame({'brand_tags':brand_tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "ef68262a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>New Specs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>ROYAL SON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Elligator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Fastrack</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           brand_tags\n",
       "0   <selenium.webdriver.remote.webelement.WebEleme...\n",
       "1   <selenium.webdriver.remote.webelement.WebEleme...\n",
       "2   <selenium.webdriver.remote.webelement.WebEleme...\n",
       "3   <selenium.webdriver.remote.webelement.WebEleme...\n",
       "4   <selenium.webdriver.remote.webelement.WebEleme...\n",
       "..                                                ...\n",
       "75                                          New Specs\n",
       "76                                          ROYAL SON\n",
       "77                                      VINCENT CHASE\n",
       "78                                          Elligator\n",
       "79                                           Fastrack\n",
       "\n",
       "[80 rows x 1 columns]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a1b161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
